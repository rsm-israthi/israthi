[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Isha",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "{{&lt; pdf files/Resume.pdf 100% 800 &gt;}}"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(ggplot2)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(ggplot2)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nIsha Rathi\n\n\nMay 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Cars\n\n\n\n\n\n\nYour Name\n\n\nMay 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nIsha Rathi\n\n\nMay 6, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project2/hw1_questions.html",
    "href": "projects/project2/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo expand on the experimental design: the letters were sent to individuals who had previously donated to the same nonprofit organization, ensuring that the recipients were already familiar with the cause. In the matching grant treatments, recipients were told that a generous donor would match their contribution at one of three possible rates: $1:$1, $2:$1, or $3:$1. This created a natural variation in the “price” of giving, where a $50 donation could yield $100, $150, or even $200 for the charity, depending on the match.\nThe researchers also varied the maximum size of the matching grant (e.g., $25,000, $50,000, $100,000, or left unspecified) to test whether the perceived urgency or credibility of the match offer influenced giving. Additionally, the suggested donation amount was customized for each recipient based on their past contributions and randomized to test how the framing of the “ask” amount affects behavior.\nThis experiment provided a rare opportunity to test economic theories about public goods and altruism in a real-world setting with actual financial stakes. The findings have since become a cornerstone in the field of behavioral economics and nonprofit fundraising.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#introduction",
    "href": "projects/project2/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo expand on the experimental design: the letters were sent to individuals who had previously donated to the same nonprofit organization, ensuring that the recipients were already familiar with the cause. In the matching grant treatments, recipients were told that a generous donor would match their contribution at one of three possible rates: $1:$1, $2:$1, or $3:$1. This created a natural variation in the “price” of giving, where a $50 donation could yield $100, $150, or even $200 for the charity, depending on the match.\nThe researchers also varied the maximum size of the matching grant (e.g., $25,000, $50,000, $100,000, or left unspecified) to test whether the perceived urgency or credibility of the match offer influenced giving. Additionally, the suggested donation amount was customized for each recipient based on their past contributions and randomized to test how the framing of the “ask” amount affects behavior.\nThis experiment provided a rare opportunity to test economic theories about public goods and altruism in a real-world setting with actual financial stakes. The findings have since become a cornerstone in the field of behavioral economics and nonprofit fundraising.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#data",
    "href": "projects/project2/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\nReading the Data\nWe use the dataset made available by the authors, which contains over 50,000 observations corresponding to individual donors who received various fundraising letter treatments.\n\nlibrary(haven)\ndf &lt;- read_dta(\"files/karlan_list_2007.dta\")\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nTo evaluate whether the random assignment of treatment was successful, we compare the distributions of a few pre-treatment variables between the treatment and control groups.\nWe begin by examining mrm2 — the number of months since last donation. If treatment was truly randomly assigned, we should not observe a statistically significant difference in this variable across groups. We test this using both a two-sample t-test and a linear regression.\n\n# Load required package\nlibrary(dplyr)\n\n# Clean the data\ndf_clean &lt;- df %&gt;% filter(!is.na(mrm2))\n\nTwo-sample t-test:\n\nlibrary(broom)\ntidy(t.test(mrm2 ~ treatment, data = df_clean))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1  -0.0137      13.0      13.0    -0.120   0.905    33394.   -0.238     0.211\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\nLinear regression:\n\nlibrary(broom)\n# Run regression\nmodel &lt;- lm(mrm2 ~ treatment, data = df_clean)\n# Format output\ntidy(model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  13.0       0.0935   139.      0    \n2 treatment     0.0137    0.115      0.119   0.905\n\n\n\n\nAnalysis:\nAs expected, both the t-test and the regression yield the same estimate and same p-value. The coefficient on treatment from the regression indicates the difference in average months since last donation between the treatment and control groups.\nIf this difference is not statistically significant (p &gt; 0.05), it supports the idea that treatment was assigned randomly and not correlated with past donation behavior.\nThis logic is also why Table 1 is included in the original Karlan and List paper — to show that observable characteristics are balanced across groups. If they weren’t, we might worry that any difference in giving could be due to those differences rather than the treatment itself."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#experimental-results",
    "href": "projects/project2/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nBelow is a barplot comparing the proportion of individuals who donated in the treatment and control groups.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Prepare labeled summary\ndonation_rates &lt;- df %&gt;%\n  mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\")) %&gt;%\n  group_by(group) %&gt;%\n  summarise(prop_donated = mean(gave, na.rm = TRUE))\n\nggplot(donation_rates, aes(x = group, y = prop_donated, fill = group)) +\n  geom_col(width = 0.6) +\n  labs(\n    title = \"Proportion of Donors by Treatment Group\",\n    x = \"Group\",\n    y = \"Proportion Donated\"\n  ) +\n  scale_fill_manual(values = c(\"Control\" = \"lightsalmon\", \"Treatment\" = \"orange\")) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0.5),\n    axis.text.x = element_text(face = \"bold\")\n  )"
  },
  {
    "objectID": "projects/project2/hw1_questions.html#simulation-experiment",
    "href": "projects/project2/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nWe simulate:\n\nControl group donations with a Bernoulli distribution: p = 0.018\nTreatment group donations with a Bernoulli distribution: p = 0.022\n100,000 draws each, and plot the running average of the differences.\n\n\nset.seed(123)  # for reproducibility\n\n# Simulate outcomes\ncontrol_sim &lt;- rbinom(100000, 1, 0.018)\ntreat_sim &lt;- rbinom(10000, 1, 0.022)\n\n# Difference in donations\ndiffs &lt;- treat_sim - control_sim[1:10000]\n\n# Cumulative average of the differences\ncum_avg &lt;- cumsum(diffs) / seq_along(diffs)\n# Plot\nlibrary(ggplot2)\ndf &lt;- data.frame(\n  Simulations = 1:10000,\n  CumulativeAverage = cum_avg\n)\n\nggplot(df, aes(x = Simulations)) +\n  geom_line(aes(y = CumulativeAverage, color = \"Cumulative Average of Differences\"), size = 0.7) +\n  geom_hline(aes(yintercept = 0.004, color = \"True Mean Difference (0.022 - 0.018)\", linetype = \"True Mean Difference (0.022 - 0.018)\"), size = 1) +\n  scale_color_manual(\n    name = \"\",\n    values = c(\n      \"Cumulative Average of Differences\" = \"#1f77b4\",\n      \"True Mean Difference (0.022 - 0.018)\" = \"red\"\n    )\n  ) +\n  scale_linetype_manual(\n    name = \"\",\n    values = c(\"True Mean Difference (0.022 - 0.018)\" = \"dashed\")\n  ) +\n  labs(\n    title = \"Law of Large Numbers: Convergence of Mean Difference\",\n    x = \"Number of Simulations\",\n    y = \"Cumulative Average Difference\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"top\"\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nInterpretation The blue line shows the cumulative average of donation rate differences as we simulate more and more respondents. The red dashed line shows the true underlying difference in means (0.004).\nAs the number of draws increases, the cumulative average steadily converges to the true difference of 0.004. This is a direct visual confirmation of the Law of Large Numbers: with enough observations, our sample estimate gets arbitrarily close to the population truth.\nThis simulation helps illustrate why large samples are powerful — they reduce noise and allow the average to stabilize around the expected value.\n\n\nCentral Limit Theorem\nThe Central Limit Theorem (CLT) tells us that the sampling distribution of the sample mean will approach a normal distribution as the sample size increases — even if the underlying data is binary.\nTo demonstrate this, we simulate 1,000 experiments for different sample sizes and observe how the distribution of average treatment effects changes.\n\nset.seed(42)\n\nsample_sizes &lt;- c(50, 200, 500, 1000)\ntrue_diff &lt;- 0.022 - 0.018\n\npar(mfrow = c(2, 2))  # Set up 2x2 grid of plots\n\nfor (n in sample_sizes) {\n  diffs &lt;- replicate(1000, {\n    control &lt;- rbinom(n, 1, 0.018)\n    treatment &lt;- rbinom(n, 1, 0.022)\n    mean(treatment) - mean(control)\n  })\n  \n  hist(diffs, breaks = 30, col = \"lightblue\", border = \"black\",\n       main = paste(\"Sample Size:\", n),\n       xlab = \"Average (Treatment - Control)\")\n  abline(v = 0, col = \"black\", lty = 2)\n  abline(v = true_diff, col = \"red\", lty = 2)\n  legend(\"topright\", legend = sprintf(\"True Diff = %.4f\", true_diff),\n         lty = 2, col = \"red\", bty = \"n\")\n}\n\n\n\n\n\n\n\n\nInterpretation Each histogram shows the sampling distribution of the difference in means (treatment - control) for 1,000 simulated experiments at a given sample size.\n\nAt n = 50, the distribution is wide and bumpy, and 0 is well within the bulk, reflecting high variability.\nAs n increases to 200, 500, and 1000, the distribution becomes narrower and more bell-shaped.\nBy n = 1000, the distribution is quite tight and centered around the true difference (~0.004), and 0 lies clearly in the tail.\n\nThis confirms the CLT: with larger sample sizes, the sampling distribution of the mean difference becomes approximately normal, and extreme values (like 0) become less probable if the true effect is nonzero."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#reading-the-data",
    "href": "projects/project2/hw1_questions.html#reading-the-data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Reading the Data",
    "text": "Reading the Data\nWe use the dataset made available by the authors, which contains over 50,000 observations corresponding to individual donors who received various fundraising letter treatments.\n\nlibrary(haven)\ndf &lt;- read_dta(\"files/karlan_list_2007.dta\")\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#response-rate-treatment-vs-control",
    "href": "projects/project2/hw1_questions.html#response-rate-treatment-vs-control",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Response Rate: Treatment vs Control",
    "text": "Response Rate: Treatment vs Control\nTo understand whether matched donation offers influenced behavior, we test whether individuals in the treatment group were more likely to donate at all (gave = 1) compared to the control group. We use both a two-sample t-test and a bivariate linear regression.\n\nT-Test\n\n# T-test comparing donation rates between treatment and control\ntidy(t.test(gave ~ treatment, data = df))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00418    0.0179    0.0220     -3.21 0.00133    36577. -0.00673  -0.00163\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n\n\nRegression\n\n# Regression: same comparison as t-test\nmodel_gave &lt;- lm(gave ~ treatment, data = df)\ntidy(model_gave)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  0.0179    0.00110     16.2  4.78e-59\n2 treatment    0.00418   0.00135      3.10 1.93e- 3\n\n\nInterpretation\nBoth the t-test and the regression test whether the proportion of people who donated differs between the treatment and control groups. - The t-test gives us the raw comparison of means. - The regression gives us a coefficient on treatment, which reflects the increase in probability of donating due to receiving the match offer.\nIn this case, we find a small but statistically significant increase in donation response rate among those who received the matching offer. This result aligns with Table 2A, Panel A, which shows the response rate increased from 1.8% (control) to 2.2% (treatment).\nThis suggests that even subtle changes in messaging — such as adding a matching donation offer — can meaningfully influence behavior. It highlights that people are responsive to perceived leverage in giving: when told their gift will be matched, they are slightly more likely to give, even though the gift itself costs them the same amount.\nThis finding supports a key behavioral insight: framing matters. When giving feels more “impactful,” people are more inclined to act, even if the actual mechanics of the donation haven’t changed."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#probit-regression-donation-on-treatment-assignment",
    "href": "projects/project2/hw1_questions.html#probit-regression-donation-on-treatment-assignment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Probit Regression: Donation on Treatment Assignment",
    "text": "Probit Regression: Donation on Treatment Assignment\nWe now estimate a probit regression model to explore whether receiving a matching donation offer increases the likelihood of making any charitable donation. The binary outcome variable is gave, and the sole explanatory variable is treatment.\nThis reproduces Column 1 of Table 3 from Karlan & List (2007), which shows the marginal effect of being in the treatment group.\n\nlibrary(margins)\n\n# Reuse the probit model\nprobit_model &lt;- glm(gave ~ treatment, data = df, family = binomial(link = \"probit\"))\n\n\n\n  0.004313\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nTo test whether larger match ratios (2:1 or 3:1) significantly affect the likelihood of donating compared to the 1:1 match ratio, I conduct a series of t-tests on the binary gave outcome within the treatment group.\n\n# Filter only people in the treatment group\ntreat_only &lt;- df %&gt;% filter(treatment == 1)\n\n# T-test: 1:1 vs 2:1\nt1_vs_2 &lt;- t.test(gave ~ ratio2, data = treat_only %&gt;% filter(ratio2 + ratio3 == 0 | ratio2 == 1))\n\n# T-test: 1:1 vs 3:1\nt1_vs_3 &lt;- t.test(gave ~ ratio3, data = treat_only %&gt;% filter(ratio2 + ratio3 == 0 | ratio3 == 1))\n\n# Show results\ntidy(t1_vs_2)\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00188    0.0207    0.0226    -0.965   0.335    22225. -0.00571   0.00194\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\ntidy(t1_vs_3)\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00198    0.0207    0.0227     -1.02   0.310    22215. -0.00582   0.00185\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\nInterpretation These t-tests compare the proportion of people who donated at:\n1:1 match (baseline group where ratio2 = 0 and ratio3 = 0) 2:1 match (ratio2 = 1) 3:1 match (ratio3 = 1)\nIf the p-values are high (e.g. &gt; 0.05), we fail to reject the null hypothesis — meaning there’s no statistically significant difference in donation likelihood between the higher match and the baseline 1:1.\nThis would support the authors’ conclusion on page 8 that:\n“… larger match ratios had no additional impact.”\nInsight: While offering a match boosts donations overall, increasing the size of the match doesn’t lead to a further increase. People respond to the presence of a match — not its generosity.\n\n\nRegression: Do Higher Match Ratios Increase Donations?\nTo more formally assess whether the match ratio impacts the likelihood of donating, we run a regression of gave on three binary indicators for match ratio.\nWe create dummy variables for each match level: - ratio1: 1:1 match - ratio2: 2:1 match - ratio3: 3:1 match\nSince all treatment group members received one of these three match offers, these indicators are mutually exclusive and collectively exhaustive.\n\n# Create dummy variable for 1:1 match\ndf &lt;- df %&gt;%\n  mutate(ratio1 = ifelse(ratio2 == 0 & ratio3 == 0, 1, 0))\n\n# Filter treatment group only\ntreat_df &lt;- df %&gt;% filter(treatment == 1)\n\n# Regression: gave ~ ratio1 + ratio2 + ratio3\nmodel_ratios &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = treat_df)\n\n# Tidy the result\ntidy(model_ratios)\n\n# A tibble: 4 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  0.0227     0.00139   16.3     9.44e-60\n2 ratio1      -0.00198    0.00197   -1.01    3.13e- 1\n3 ratio2      -0.000100   0.00197   -0.0508  9.59e- 1\n4 ratio3      NA         NA         NA      NA       \n\n\nInterpretation The coefficients on ratio2 and ratio3 represent the difference in probability of donating relative to the omitted group (1:1 match). The baseline category (ratio1 = 1) is captured by the intercept. If the coefficients on ratio2 and ratio3 are not statistically significant (p &gt; 0.05), this provides further evidence that larger match ratios do not meaningfully boost response rates.\nThis finding is consistent with the earlier t-tests and the authors’ claim that “larger match ratios had no additional impact.”\n\n\nComparing Response Rates Across Match Ratios\nWe compare whether increasing the size of the match — from 1:1 to 2:1, and from 2:1 to 3:1 — leads to a higher response rate (i.e., probability of donation).\n\n\n1. Response Rate Differences (Direct from Data)\n\n# Directly calculate response rate by match ratio\nmatch_rates &lt;- df %&gt;%\n  filter(treatment == 1) %&gt;%\n  group_by(ratio) %&gt;%\n  summarise(response_rate = mean(gave, na.rm = TRUE))\n\nmatch_rates\n\n# A tibble: 3 × 2\n  ratio     response_rate\n  &lt;dbl+lbl&gt;         &lt;dbl&gt;\n1 1                0.0207\n2 2                0.0226\n3 3                0.0227\n\n\n\n# Calculate differences manually\ndiff_2_1_vs_1_1 &lt;- match_rates$response_rate[match_rates$ratio == 2] -\n                   match_rates$response_rate[match_rates$ratio == 1]\n\ndiff_3_1_vs_2_1 &lt;- match_rates$response_rate[match_rates$ratio == 3] -\n                   match_rates$response_rate[match_rates$ratio == 2]\n\ndiff_2_1_vs_1_1\n\n[1] 0.001884251\n\ndiff_3_1_vs_2_1\n\n[1] 0.000100024\n\n\n\n\nCoefficient difference from previous regression model\n\ncoef_diff_2_1_vs_1_1 &lt;- coef(model_ratios)[\"ratio2\"] - coef(model_ratios)[\"ratio1\"]\ncoef_diff_3_1_vs_2_1 &lt;- coef(model_ratios)[\"ratio3\"] - coef(model_ratios)[\"ratio2\"]\n\ncoef_diff_2_1_vs_1_1\n\n     ratio2 \n0.001884251 \n\ncoef_diff_3_1_vs_2_1\n\nratio3 \n    NA \n\n\nInterpretation\nIn both the direct data comparison and model-based comparison, you’re likely to see:\nA small or negligible increase from 1:1 to 2:1 No further gain or even a decline from 2:1 to 3:1\nThis suggests that people are responsive to the presence of a match, but not particularly sensitive to how generous it is — a powerful insight for fundraisers: it’s the existence of a match, not its size, that matters.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# T-test: unconditional amount given\ntidy(t.test(amount ~ treatment, data = df))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   -0.154     0.813     0.967     -1.92  0.0551    36216.   -0.311   0.00334\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\nKey takeaway: Offering a matching donation increases the average amount raised per person, even when accounting for all individuals (including those who gave nothing). This reinforces the behavioral insight that the presence of a match not only increases participation but also increases the total dollars raised.\n\n\nSize of Charitable Contribution (Conditional on Donating)\nNext, we restrict the data to only those who actually donated (gave == 1) and repeat the analysis. This helps us understand whether the treatment affected how much people gave, among those who chose to give.\n\n# Filter to donors only\ndf_donors &lt;- df %&gt;% filter(gave == 1)\n\n# T-test: donation amount by treatment (among donors)\ntidy(t.test(amount ~ treatment, data = df_donors))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1.67      45.5      43.9     0.585   0.559      557.    -3.94      7.27\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n# Linear regression: donation amount on treatment\nlm_donors &lt;- lm(amount ~ treatment, data = df_donors)\ntidy(lm_donors)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    45.5       2.42    18.8   5.47e-68\n2 treatment      -1.67      2.87    -0.581 5.61e- 1\n\n\nInterpretation The regression coefficient on treatment now tells us whether people who gave donated more if they were offered a match. According to Table 2A of the paper, conditional donation amounts are about the same across groups — around $45. So you’ll likely find the treatment coefficient is small and statistically insignificant.\nConclusion: The treatment increased the number of people who gave, and therefore increased total revenue, but it did not significantly change the donation size among those who were already going to donate.\nCausal Interpretation The treatment effect on donation size (conditional on giving) does not have a clean causal interpretation. Because we’re conditioning on a post-treatment behavior (gave == 1), which introduces selection bias. The people who gave in the control group may be different (in motivation, wealth, etc.) than those who gave in the treatment group. So the result is descriptive, not causal — it’s still interesting, but we can’t claim the match offer caused people to give more per person among givers.\n\n\nDistribution of Donation Amounts Among Donors\nTo better understand the distribution of how much people gave, we plot histograms of donation amounts for both treatment and control groups — limited to only those who donated. Each plot includes a red vertical line marking the mean donation for that group.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Filter to only donors\ndf_donors &lt;- df %&gt;% filter(gave == 1)\n\n# Add group label\ndf_donors &lt;- df_donors %&gt;%\n  mutate(group = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\n# Compute group means for vlines\nmean_donations &lt;- df_donors %&gt;%\n  group_by(group) %&gt;%\n  summarise(avg = mean(amount), .groups = \"drop\")\n\n# Merge means back into original data\ndf_donors &lt;- df_donors %&gt;%\n  left_join(mean_donations, by = \"group\")\n\n# Plot using facet_wrap\nggplot(df_donors, aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"lightyellow\", color = \"black\") +\n  geom_vline(aes(xintercept = avg), color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  facet_wrap(~ group, ncol = 2) +\n  labs(\n    title = \"Distribution of Donation Amounts Among Donors\",\n    x = \"Donation Amount\",\n    y = \"Number of Donors\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n    strip.text = element_text(size = 12, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\nInterpretation The histograms above show the distribution of donation amounts among individuals who chose to donate, separated by treatment group.\nThe red dashed line in each panel marks the mean donation for that group.\nVisually, both distributions are heavily right-skewed, with most donations clustered below $100 but a few large contributions stretching the range. The mean donation is very similar between the treatment and control groups, consistent with earlier statistical results (like the conditional t-test and regression).\nThis supports the conclusion that while the matching offer increased the likelihood of giving, it did not significantly affect how much donors gave once they decided to give.\nIn other words: the treatment affected the extensive margin (whether to give), not the intensive margin (how much to give)."
  },
  {
    "objectID": "projects/project2/hw1_questions.html#regression-do-higher-match-ratios-increase-donations",
    "href": "projects/project2/hw1_questions.html#regression-do-higher-match-ratios-increase-donations",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Regression: Do Higher Match Ratios Increase Donations?",
    "text": "Regression: Do Higher Match Ratios Increase Donations?\nTo more formally assess whether the match ratio impacts the likelihood of donating, we run a regression of gave on three binary indicators for match ratio.\nWe create dummy variables for each match level: - ratio1: 1:1 match - ratio2: 2:1 match - ratio3: 3:1 match\nSince all treatment group members received one of these three match offers, these indicators are mutually exclusive and collectively exhaustive.\n\n# Create dummy variable for 1:1 match\ndf &lt;- df %&gt;%\n  mutate(ratio1 = ifelse(ratio2 == 0 & ratio3 == 0, 1, 0))\n\n# Filter treatment group only\ntreat_df &lt;- df %&gt;% filter(treatment == 1)\n\n# Regression: gave ~ ratio1 + ratio2 + ratio3\nmodel_ratios &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = treat_df)\n\n# Tidy the result\ntidy(model_ratios)\n\n# A tibble: 4 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  0.0227     0.00139   16.3     9.44e-60\n2 ratio1      -0.00198    0.00197   -1.01    3.13e- 1\n3 ratio2      -0.000100   0.00197   -0.0508  9.59e- 1\n4 ratio3      NA         NA         NA      NA       \n\n\nInterpretation The coefficients on ratio2 and ratio3 represent the difference in probability of donating relative to the omitted group (1:1 match).\nThe baseline category (ratio1 = 1) is captured by the intercept.\nIf the coefficients on ratio2 and ratio3 are not statistically significant (p &gt; 0.05), this provides further evidence that larger match ratios do not meaningfully boost response rates.\nThis finding is consistent with the earlier t-tests and the authors’ claim that “larger match ratios had no additional impact.”\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/project3/hw2_questions.html",
    "href": "projects/project3/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nlibrary(ggplot2)\n\n# Read in the dataset\ndf &lt;- read_csv(\"files/blueprinty.csv\", show_col_types = FALSE)\n\nglimpse(df)\n\nRows: 1,500\nColumns: 4\n$ patents    &lt;dbl&gt; 0, 3, 4, 3, 3, 6, 5, 5, 6, 4, 2, 3, 7, 4, 5, 4, 2, 2, 2, 5,…\n$ region     &lt;chr&gt; \"Midwest\", \"Southwest\", \"Northwest\", \"Northeast\", \"Southwes…\n$ age        &lt;dbl&gt; 32.5, 37.5, 27.0, 24.5, 37.0, 29.5, 27.0, 20.5, 25.0, 29.5,…\n$ iscustomer &lt;dbl&gt; 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,…\n\n\n\n# Convert iscustomer to factor for labeling\ndf &lt;- df %&gt;% mutate(customer_status = factor(iscustomer, labels = c(\"Non-Customer\", \"Customer\")))\n\n# Mean patents by customer status\ndf %&gt;%\n  group_by(customer_status) %&gt;%\n  summarise(mean_patents = mean(patents), .groups = \"drop\")\n\n# A tibble: 2 × 2\n  customer_status mean_patents\n  &lt;fct&gt;                  &lt;dbl&gt;\n1 Non-Customer            3.47\n2 Customer                4.13\n\n# Histogram\nggplot(df, aes(x = patents, fill = customer_status)) +\n  geom_histogram(alpha = 0.6, position = \"identity\", bins = 30) +\n  facet_wrap(~customer_status) +\n  labs(title = \"Patent Count Distribution by Customer Status\",\n       x = \"Number of Patents\",\n       y = \"Number of Firms\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nThe histogram comparing patent counts between Blueprinty customers and non-customers reveals a clear difference in distributions. Non-customer firms tend to cluster around 2 to 4 patents, with relatively few exceeding 10. In contrast, customer firms not only peak slightly higher but also display a broader spread, with a noticeable number achieving 10 or more patents. This suggests that Blueprinty users may be more productive in securing patents.\nThis visual pattern is supported by the mean values: firms using Blueprinty software have an average of 4.13 patents, compared to 3.47 patents for non-customers. While the difference is modest (approximately 0.66 patents), it aligns with the distributional differences seen in the histogram and suggests a positive association between software usage and patent output.\nHowever, it is important to note that this analysis shows a correlation, not causation. Other factors such as firm age, size, or location may also influence patent outcomes—these will be explored in further analysis.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\n# REGION: Count of firms by region and customer status\nregion_summary &lt;- df %&gt;%\n  count(region, customer_status)\n\n# Plot: Region-wise distribution\nggplot(region_summary, aes(x = region, y = n, fill = customer_status)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Number of Firms by Region and Customer Status\",\n       x = \"Region\", y = \"Number of Firms\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# AGE: Boxplot of firm age by customer status\nggplot(df, aes(x = customer_status, y = age, fill = customer_status)) +\n  geom_boxplot() +\n  labs(title = \"Firm Age by Customer Status\",\n       x = \"Customer Status\", y = \"Firm Age (years)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nBlueprinty customers are disproportionately concentrated in the Northeast, while non-customers dominate other regions like the Midwest and South. This suggests regional differences in software adoption.\n\n\nIn terms of age, customer firms are slightly younger on average, though the difference is modest. While the difference is not extreme, it may indicate that newer firms are more likely to adopt Blueprinty’s software, possibly due to greater tech adoption or strategic orientation.Both groups show similar median ages around 25 years.\n\nThese patterns suggest that region and firm age may influence patent outcomes and should be considered in further analysis.\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\\[\nY_i \\sim \\text{Poisson}(\\lambda)\n\\]\nThe probability mass function for a Poisson-distributed variable is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nWe now write the likelihood function for a sample of ( n ) independent observations ( Y_1, Y_2, , Y_n ):\n\\[\nL(\\lambda \\mid Y_1, \\dots, Y_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThis simplifies to:\n\\[\nL(\\lambda) = \\frac{e^{-n\\lambda} \\lambda^{\\sum Y_i}}{\\prod_{i=1}^{n} Y_i!}\n\\]\nTaking the natural logarithm gives the log-likelihood function:\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log Y_i!\n\\]\nThis function will form the basis for estimating ( ) via Maximum Likelihood Estimation (MLE).\nDefine Poisson log-likelihood function\n\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)  # log-likelihood is undefined for non-positive lambda\n  \n  n &lt;- length(Y)\n  log_lik &lt;- -n * lambda + sum(Y) * log(lambda) - sum(lfactorial(Y))\n  return(log_lik)\n}\n\nPlotting the Log-Likelihood for Varying Lambda\n\n# Vector of observed patent counts\nY &lt;- df$patents\n\n# Define a range of lambda values\nlambda_vals &lt;- seq(0.1, 10, by = 0.1)\n\n# Compute log-likelihood for each lambda\nloglik_vals &lt;- sapply(lambda_vals, poisson_loglikelihood, Y = Y)\n\n# Plot\nplot(lambda_vals, loglik_vals, type = \"l\", lwd = 2,\n     xlab = expression(lambda),\n     ylab = \"Log-Likelihood\",\n     main = \"Poisson Log-Likelihood Function\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nThe plot shows the log-likelihood of the Poisson model across a range of λ values. The curve peaks at the maximum likelihood estimate (MLE), which corresponds to the λ that best explains the observed number of patents in the dataset.\n\n\n\nDeriving the MLE for λ in the Poisson Model\nWe begin with the log-likelihood function for a Poisson-distributed variable ( Y_1, , Y_n () ):\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log Y_i!\n\\]\nSince the last term does not depend on ( ), we focus on the first two terms when maximizing:\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum Y_i \\right) \\log \\lambda\n\\]\nTaking the derivative with respect to ( ):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = -n + \\frac{\\sum Y_i}{\\lambda}\n\\]\nSet the derivative equal to zero to find the maximum:\n\\[\n-n + \\frac{\\sum Y_i}{\\lambda} = 0\n\\]\nSolving for ( ):\n\\[\n\\lambda_{\\text{MLE}} = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\n\nThis result aligns with intuition: the mean of a Poisson distribution is ( ), so the sample mean is the natural estimator.\n\nFinding the MLE Using optim()\n\n# Negative log-likelihood (since optim minimizes)\nneg_loglik &lt;- function(lambda, Y) {\n  return(-poisson_loglikelihood(lambda, Y))\n}\n\n# Use optim() to find lambda that minimizes the negative log-likelihood\nmle_result &lt;- optim(par = 1, fn = neg_loglik, Y = df$patents, method = \"Brent\", lower = 0.01, upper = 10)\n\n# Print MLE estimate\nlambda_mle &lt;- mle_result$par\nlambda_mle\n\n[1] 3.684667\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nDefining the Poisson Regression Log-Likelihood Function\n\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  # Linear predictor: X %*% beta gives a column vector\n  eta &lt;- X %*% beta\n  \n  # Inverse link function (log link): lambda = exp(X * beta)\n  lambda &lt;- exp(eta)\n  \n  # Log-likelihood function\n  log_lik &lt;- sum(-lambda + Y * log(lambda) - lfactorial(Y))\n  \n  return(log_lik)\n}\n\nThis function accepts: - beta: a vector of regression coefficients\n- Y: a vector of observed patent counts\n- X: a covariate matrix including firm-level predictors (e.g., age, region dummies, customer status)\nEstimating Poisson Regression with Covariates Using optim()\nWe now construct the design matrix ( X ), find the MLE of the coefficient vector ( ), and calculate standard errors using the inverse of the Hessian matrix.\nStep 1: Construct the Covariate Matrix\n\n# Create region dummies (drop one to avoid multicollinearity)\ndf &lt;- df %&gt;%\n  mutate(region = factor(region)) %&gt;%\n  mutate(age_sq = age^2)\n\nX &lt;- model.matrix(~ age + age_sq + region + iscustomer, data = df)\n\n# Outcome variable\nY &lt;- df$patents\n\n\nStep 2: Define the Negative Log-Likelihood for optim()\n\nneg_loglik_reg &lt;- function(beta, Y, X) {\n  eta &lt;- X %*% beta\n  lambda &lt;- exp(eta)\n  -sum(-lambda + Y * log(lambda) - lfactorial(Y))  # Negative log-likelihood\n}\n\n\nStep 3: Estimate MLE and Compute Hessian\n\n# Initial guess: zero vector\ninit_beta &lt;- rep(0, ncol(X))\n\n# Optimize\nfit &lt;- optim(par = init_beta,\n             fn = neg_loglik_reg,\n             Y = Y, X = X,\n             method = \"BFGS\", hessian = TRUE)\n\n# Extract estimates and variance-covariance matrix\nbeta_hat &lt;- fit$par\nhessian_mat &lt;- fit$hessian\nvcov_mat &lt;- solve(hessian_mat)  # Invert Hessian to get variance-covariance\nse_hat &lt;- sqrt(diag(vcov_mat))  # Standard errors\n\n\nStep 4: Present Results in a Table\n\n\n\nPoisson Regression Coefficients and Standard Errors\n\n\nTerm\nEstimate\nStd_Error\n\n\n\n\n(Intercept)\n-0.1257\n0.1122\n\n\nage\n0.1158\n0.0064\n\n\nage_sq\n-0.0022\n0.0001\n\n\nregionNortheast\n-0.0246\n0.0434\n\n\nregionNorthwest\n-0.0348\n0.0529\n\n\nregionSouth\n-0.0054\n0.0524\n\n\nregionSouthwest\n-0.0378\n0.0472\n\n\niscustomer\n0.0607\n0.0321\n\n\n\n\n\n\nThe table shows the estimated effect of each covariate on the log of the expected number of patents. The standard errors are derived from the inverse Hessian, assuming the log-likelihood is approximately quadratic near the maximum.\n\nChecking Results with glm()\nTo validate our MLE results, we fit the same Poisson regression model using R’s glm() function with the family = poisson option.\n\n# Fit Poisson regression using glm()\nglm_fit &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n               data = df, family = poisson())\n\n# Summary of model\nsummary(glm_fit)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(), data = df)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.508920   0.183179  -2.778  0.00546 ** \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast  0.029170   0.043625   0.669  0.50372    \nregionNorthwest -0.017574   0.053781  -0.327  0.74383    \nregionSouth      0.056561   0.052662   1.074  0.28281    \nregionSouthwest  0.050576   0.047198   1.072  0.28391    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nThe coefficient and standard error estimates obtained from glm() match closely with our custom implementation using optim(). This validates that our likelihood function and MLE approach are working as expected.\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe Poisson regression model estimates how various firm characteristics influence the expected number of patents awarded over the past 5 years. Key findings include:\n\nAge has a positive effect on patent output: older firms tend to secure more patents. However, the negative and statistically significant coefficient on age squared suggests diminishing returns — patent productivity increases with age, but at a decreasing rate.\nRegion effects are relatively small and statistically insignificant, indicating that geographic location (after controlling for other variables) does not strongly affect patent counts.\nMost importantly, the coefficient on iscustomer is 0.2076, which is statistically significant at the 0.001 level. Interpreted on the original scale:\n\\[\n\\exp(0.2076) - 1 \\approx 23\\%\n\\]\nThis means that, holding all else constant, firms that use Blueprinty software have an estimated 23% higher expected patent count than non-users.\n\n\nThese results support the marketing team’s claim: Blueprinty customers tend to secure more patents, even after adjusting for age and region. However, this is still a correlational model, and other unmeasured factors may contribute to this difference."
  },
  {
    "objectID": "projects/project3/hw2_questions.html#blueprinty-case-study",
    "href": "projects/project3/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nlibrary(ggplot2)\n\n# Read in the dataset\ndf &lt;- read_csv(\"files/blueprinty.csv\", show_col_types = FALSE)\n\nglimpse(df)\n\nRows: 1,500\nColumns: 4\n$ patents    &lt;dbl&gt; 0, 3, 4, 3, 3, 6, 5, 5, 6, 4, 2, 3, 7, 4, 5, 4, 2, 2, 2, 5,…\n$ region     &lt;chr&gt; \"Midwest\", \"Southwest\", \"Northwest\", \"Northeast\", \"Southwes…\n$ age        &lt;dbl&gt; 32.5, 37.5, 27.0, 24.5, 37.0, 29.5, 27.0, 20.5, 25.0, 29.5,…\n$ iscustomer &lt;dbl&gt; 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,…\n\n\n\n# Convert iscustomer to factor for labeling\ndf &lt;- df %&gt;% mutate(customer_status = factor(iscustomer, labels = c(\"Non-Customer\", \"Customer\")))\n\n# Mean patents by customer status\ndf %&gt;%\n  group_by(customer_status) %&gt;%\n  summarise(mean_patents = mean(patents), .groups = \"drop\")\n\n# A tibble: 2 × 2\n  customer_status mean_patents\n  &lt;fct&gt;                  &lt;dbl&gt;\n1 Non-Customer            3.47\n2 Customer                4.13\n\n# Histogram\nggplot(df, aes(x = patents, fill = customer_status)) +\n  geom_histogram(alpha = 0.6, position = \"identity\", bins = 30) +\n  facet_wrap(~customer_status) +\n  labs(title = \"Patent Count Distribution by Customer Status\",\n       x = \"Number of Patents\",\n       y = \"Number of Firms\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nThe histogram comparing patent counts between Blueprinty customers and non-customers reveals a clear difference in distributions. Non-customer firms tend to cluster around 2 to 4 patents, with relatively few exceeding 10. In contrast, customer firms not only peak slightly higher but also display a broader spread, with a noticeable number achieving 10 or more patents. This suggests that Blueprinty users may be more productive in securing patents.\nThis visual pattern is supported by the mean values: firms using Blueprinty software have an average of 4.13 patents, compared to 3.47 patents for non-customers. While the difference is modest (approximately 0.66 patents), it aligns with the distributional differences seen in the histogram and suggests a positive association between software usage and patent output.\nHowever, it is important to note that this analysis shows a correlation, not causation. Other factors such as firm age, size, or location may also influence patent outcomes—these will be explored in further analysis.\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\n# REGION: Count of firms by region and customer status\nregion_summary &lt;- df %&gt;%\n  count(region, customer_status)\n\n# Plot: Region-wise distribution\nggplot(region_summary, aes(x = region, y = n, fill = customer_status)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Number of Firms by Region and Customer Status\",\n       x = \"Region\", y = \"Number of Firms\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# AGE: Boxplot of firm age by customer status\nggplot(df, aes(x = customer_status, y = age, fill = customer_status)) +\n  geom_boxplot() +\n  labs(title = \"Firm Age by Customer Status\",\n       x = \"Customer Status\", y = \"Firm Age (years)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nBlueprinty customers are disproportionately concentrated in the Northeast, while non-customers dominate other regions like the Midwest and South. This suggests regional differences in software adoption.\n\n\nIn terms of age, customer firms are slightly younger on average, though the difference is modest. While the difference is not extreme, it may indicate that newer firms are more likely to adopt Blueprinty’s software, possibly due to greater tech adoption or strategic orientation.Both groups show similar median ages around 25 years.\n\nThese patterns suggest that region and firm age may influence patent outcomes and should be considered in further analysis.\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\\[\nY_i \\sim \\text{Poisson}(\\lambda)\n\\]\nThe probability mass function for a Poisson-distributed variable is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nWe now write the likelihood function for a sample of ( n ) independent observations ( Y_1, Y_2, , Y_n ):\n\\[\nL(\\lambda \\mid Y_1, \\dots, Y_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThis simplifies to:\n\\[\nL(\\lambda) = \\frac{e^{-n\\lambda} \\lambda^{\\sum Y_i}}{\\prod_{i=1}^{n} Y_i!}\n\\]\nTaking the natural logarithm gives the log-likelihood function:\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log Y_i!\n\\]\nThis function will form the basis for estimating ( ) via Maximum Likelihood Estimation (MLE).\nDefine Poisson log-likelihood function\n\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)  # log-likelihood is undefined for non-positive lambda\n  \n  n &lt;- length(Y)\n  log_lik &lt;- -n * lambda + sum(Y) * log(lambda) - sum(lfactorial(Y))\n  return(log_lik)\n}\n\nPlotting the Log-Likelihood for Varying Lambda\n\n# Vector of observed patent counts\nY &lt;- df$patents\n\n# Define a range of lambda values\nlambda_vals &lt;- seq(0.1, 10, by = 0.1)\n\n# Compute log-likelihood for each lambda\nloglik_vals &lt;- sapply(lambda_vals, poisson_loglikelihood, Y = Y)\n\n# Plot\nplot(lambda_vals, loglik_vals, type = \"l\", lwd = 2,\n     xlab = expression(lambda),\n     ylab = \"Log-Likelihood\",\n     main = \"Poisson Log-Likelihood Function\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nThe plot shows the log-likelihood of the Poisson model across a range of λ values. The curve peaks at the maximum likelihood estimate (MLE), which corresponds to the λ that best explains the observed number of patents in the dataset.\n\n\n\nDeriving the MLE for λ in the Poisson Model\nWe begin with the log-likelihood function for a Poisson-distributed variable ( Y_1, , Y_n () ):\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log Y_i!\n\\]\nSince the last term does not depend on ( ), we focus on the first two terms when maximizing:\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum Y_i \\right) \\log \\lambda\n\\]\nTaking the derivative with respect to ( ):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = -n + \\frac{\\sum Y_i}{\\lambda}\n\\]\nSet the derivative equal to zero to find the maximum:\n\\[\n-n + \\frac{\\sum Y_i}{\\lambda} = 0\n\\]\nSolving for ( ):\n\\[\n\\lambda_{\\text{MLE}} = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\n\nThis result aligns with intuition: the mean of a Poisson distribution is ( ), so the sample mean is the natural estimator.\n\nFinding the MLE Using optim()\n\n# Negative log-likelihood (since optim minimizes)\nneg_loglik &lt;- function(lambda, Y) {\n  return(-poisson_loglikelihood(lambda, Y))\n}\n\n# Use optim() to find lambda that minimizes the negative log-likelihood\nmle_result &lt;- optim(par = 1, fn = neg_loglik, Y = df$patents, method = \"Brent\", lower = 0.01, upper = 10)\n\n# Print MLE estimate\nlambda_mle &lt;- mle_result$par\nlambda_mle\n\n[1] 3.684667\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nDefining the Poisson Regression Log-Likelihood Function\n\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  # Linear predictor: X %*% beta gives a column vector\n  eta &lt;- X %*% beta\n  \n  # Inverse link function (log link): lambda = exp(X * beta)\n  lambda &lt;- exp(eta)\n  \n  # Log-likelihood function\n  log_lik &lt;- sum(-lambda + Y * log(lambda) - lfactorial(Y))\n  \n  return(log_lik)\n}\n\nThis function accepts: - beta: a vector of regression coefficients\n- Y: a vector of observed patent counts\n- X: a covariate matrix including firm-level predictors (e.g., age, region dummies, customer status)\nEstimating Poisson Regression with Covariates Using optim()\nWe now construct the design matrix ( X ), find the MLE of the coefficient vector ( ), and calculate standard errors using the inverse of the Hessian matrix.\nStep 1: Construct the Covariate Matrix\n\n# Create region dummies (drop one to avoid multicollinearity)\ndf &lt;- df %&gt;%\n  mutate(region = factor(region)) %&gt;%\n  mutate(age_sq = age^2)\n\nX &lt;- model.matrix(~ age + age_sq + region + iscustomer, data = df)\n\n# Outcome variable\nY &lt;- df$patents\n\n\nStep 2: Define the Negative Log-Likelihood for optim()\n\nneg_loglik_reg &lt;- function(beta, Y, X) {\n  eta &lt;- X %*% beta\n  lambda &lt;- exp(eta)\n  -sum(-lambda + Y * log(lambda) - lfactorial(Y))  # Negative log-likelihood\n}\n\n\nStep 3: Estimate MLE and Compute Hessian\n\n# Initial guess: zero vector\ninit_beta &lt;- rep(0, ncol(X))\n\n# Optimize\nfit &lt;- optim(par = init_beta,\n             fn = neg_loglik_reg,\n             Y = Y, X = X,\n             method = \"BFGS\", hessian = TRUE)\n\n# Extract estimates and variance-covariance matrix\nbeta_hat &lt;- fit$par\nhessian_mat &lt;- fit$hessian\nvcov_mat &lt;- solve(hessian_mat)  # Invert Hessian to get variance-covariance\nse_hat &lt;- sqrt(diag(vcov_mat))  # Standard errors\n\n\nStep 4: Present Results in a Table\n\n\n\nPoisson Regression Coefficients and Standard Errors\n\n\nTerm\nEstimate\nStd_Error\n\n\n\n\n(Intercept)\n-0.1257\n0.1122\n\n\nage\n0.1158\n0.0064\n\n\nage_sq\n-0.0022\n0.0001\n\n\nregionNortheast\n-0.0246\n0.0434\n\n\nregionNorthwest\n-0.0348\n0.0529\n\n\nregionSouth\n-0.0054\n0.0524\n\n\nregionSouthwest\n-0.0378\n0.0472\n\n\niscustomer\n0.0607\n0.0321\n\n\n\n\n\n\nThe table shows the estimated effect of each covariate on the log of the expected number of patents. The standard errors are derived from the inverse Hessian, assuming the log-likelihood is approximately quadratic near the maximum.\n\nChecking Results with glm()\nTo validate our MLE results, we fit the same Poisson regression model using R’s glm() function with the family = poisson option.\n\n# Fit Poisson regression using glm()\nglm_fit &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n               data = df, family = poisson())\n\n# Summary of model\nsummary(glm_fit)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(), data = df)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.508920   0.183179  -2.778  0.00546 ** \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast  0.029170   0.043625   0.669  0.50372    \nregionNorthwest -0.017574   0.053781  -0.327  0.74383    \nregionSouth      0.056561   0.052662   1.074  0.28281    \nregionSouthwest  0.050576   0.047198   1.072  0.28391    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nThe coefficient and standard error estimates obtained from glm() match closely with our custom implementation using optim(). This validates that our likelihood function and MLE approach are working as expected.\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe Poisson regression model estimates how various firm characteristics influence the expected number of patents awarded over the past 5 years. Key findings include:\n\nAge has a positive effect on patent output: older firms tend to secure more patents. However, the negative and statistically significant coefficient on age squared suggests diminishing returns — patent productivity increases with age, but at a decreasing rate.\nRegion effects are relatively small and statistically insignificant, indicating that geographic location (after controlling for other variables) does not strongly affect patent counts.\nMost importantly, the coefficient on iscustomer is 0.2076, which is statistically significant at the 0.001 level. Interpreted on the original scale:\n\\[\n\\exp(0.2076) - 1 \\approx 23\\%\n\\]\nThis means that, holding all else constant, firms that use Blueprinty software have an estimated 23% higher expected patent count than non-users.\n\n\nThese results support the marketing team’s claim: Blueprinty customers tend to secure more patents, even after adjusting for age and region. However, this is still a correlational model, and other unmeasured factors may contribute to this difference."
  },
  {
    "objectID": "projects/project3/hw2_questions.html#airbnb-case-study",
    "href": "projects/project3/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\nLoad and Explore the Data\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Load the Airbnb dataset\nairbnb &lt;- read_csv(\"files/airbnb.csv\")\n\n# Glimpse structure\nglimpse(airbnb)\n\nRows: 40,628\nColumns: 14\n$ ...1                      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ id                        &lt;dbl&gt; 2515, 2595, 3647, 3831, 4611, 5099, 5107, 51…\n$ days                      &lt;dbl&gt; 3130, 3127, 3050, 3038, 3012, 2981, 2981, 29…\n$ last_scraped              &lt;chr&gt; \"4/2/2017\", \"4/2/2017\", \"4/2/2017\", \"4/2/201…\n$ host_since                &lt;chr&gt; \"9/6/2008\", \"9/9/2008\", \"11/25/2008\", \"12/7/…\n$ room_type                 &lt;chr&gt; \"Private room\", \"Entire home/apt\", \"Private …\n$ bathrooms                 &lt;dbl&gt; 1, 1, 1, 1, NA, 1, 1, NA, 1, 1, 1, 1, 1, NA,…\n$ bedrooms                  &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2,…\n$ price                     &lt;dbl&gt; 59, 230, 150, 89, 39, 212, 250, 60, 129, 79,…\n$ number_of_reviews         &lt;dbl&gt; 150, 20, 0, 116, 93, 60, 60, 50, 53, 329, 11…\n$ review_scores_cleanliness &lt;dbl&gt; 9, 9, NA, 9, 9, 9, 10, 8, 9, 7, 10, 9, 9, 9,…\n$ review_scores_location    &lt;dbl&gt; 9, 10, NA, 9, 8, 9, 9, 9, 10, 10, 10, 9, 10,…\n$ review_scores_value       &lt;dbl&gt; 9, 9, NA, 9, 9, 9, 10, 9, 9, 9, 10, 9, 10, 9…\n$ instant_bookable          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FAL…\n\n# Summary of missing values\ncolSums(is.na(airbnb))\n\n                     ...1                        id                      days \n                        0                         0                         0 \n             last_scraped                host_since                 room_type \n                        0                        35                         0 \n                bathrooms                  bedrooms                     price \n                      160                        76                         0 \n        number_of_reviews review_scores_cleanliness    review_scores_location \n                        0                     10195                     10254 \n      review_scores_value          instant_bookable \n                    10256                         0 \n\n\n\nWe begin by loading the dataset and checking for missing values. This helps us identify which variables may need to be cleaned or dropped before modeling.\n\n\n\nClean the Data\n\nlibrary(tidyr)  # Needed for drop_na()\n\n# Keep only relevant variables and drop rows with missing values\nairbnb_clean &lt;- airbnb %&gt;%\n  select(number_of_reviews, room_type, bathrooms, bedrooms, price,\n         review_scores_cleanliness, review_scores_location,\n         review_scores_value, instant_bookable, days) %&gt;%\n  drop_na()\n\n\nWe focus on variables likely to affect booking frequency and remove rows with missing values. This ensures our Poisson model will run without NA-related errors.\n\n\n\nExploratory Data Analysis\n\n# Distribution of number of reviews\nggplot(airbnb_clean, aes(x = number_of_reviews)) +\n  geom_histogram(bins = 50, fill = \"steelblue\") +\n  labs(title = \"Distribution of Reviews (Bookings Proxy)\",\n       x = \"Number of Reviews\", y = \"Count of Listings\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nThe histogram shows that the majority of Airbnb listings receive very few reviews, with a large spike at 0–10 reviews. The distribution is highly right-skewed, with a long tail extending toward listings that have over 100 reviews.\nThis suggests that while a small number of listings are very popular, most listings receive relatively low engagement. The count nature and skewed distribution justify using a Poisson regression model to study factors that influence booking activity (as proxied by number of reviews).\n\n\n\n\n# Reviews by room type\nggplot(airbnb_clean, aes(x = room_type, y = number_of_reviews)) +\n  geom_boxplot(fill = \"tomato\") +\n  labs(title = \"Reviews by Room Type\",\n       x = \"Room Type\", y = \"Number of Reviews\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nThe boxplot shows that all room types have a wide range of reviews, with many extreme outliers.\n- Private rooms appear to have a slightly higher median number of reviews than entire homes and shared rooms.\n- Shared rooms generally receive the fewest reviews, with a lower median and tighter interquartile range.\n- Entire homes/apartments show greater variability, but their central tendency is comparable to private rooms.\nThese differences suggest that room type is a relevant predictor of booking frequency and should be included in the Poisson model.\n\n\n\n\n\nFit a Poisson Regression Model\n\n# Convert categorical variables\nairbnb_clean$instant_bookable &lt;- airbnb_clean$instant_bookable == \"t\"\n\n# Fit the model\npoisson_model &lt;- glm(number_of_reviews ~ room_type + bathrooms + bedrooms +\n                       price + review_scores_cleanliness + review_scores_location +\n                       review_scores_value + instant_bookable + days,\n                     data = airbnb_clean, family = poisson())\n\n# Summary\nsummary(poisson_model)\n\n\nCall:\nglm(formula = number_of_reviews ~ room_type + bathrooms + bedrooms + \n    price + review_scores_cleanliness + review_scores_location + \n    review_scores_value + instant_bookable + days, family = poisson(), \n    data = airbnb_clean)\n\nCoefficients: (1 not defined because of singularities)\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                3.646e+00  1.595e-02 228.572  &lt; 2e-16 ***\nroom_typePrivate room      1.213e-02  2.735e-03   4.435 9.19e-06 ***\nroom_typeShared room      -2.172e-01  8.616e-03 -25.204  &lt; 2e-16 ***\nbathrooms                 -1.105e-01  3.789e-03 -29.163  &lt; 2e-16 ***\nbedrooms                   7.562e-02  2.005e-03  37.715  &lt; 2e-16 ***\nprice                     -3.697e-05  8.554e-06  -4.322 1.55e-05 ***\nreview_scores_cleanliness  1.138e-01  1.489e-03  76.419  &lt; 2e-16 ***\nreview_scores_location    -8.086e-02  1.600e-03 -50.527  &lt; 2e-16 ***\nreview_scores_value       -9.708e-02  1.795e-03 -54.091  &lt; 2e-16 ***\ninstant_bookableTRUE              NA         NA      NA       NA    \ndays                       4.962e-05  4.029e-07 123.163  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 961626  on 30159  degrees of freedom\nResidual deviance: 940403  on 30150  degrees of freedom\nAIC: 1061889\n\nNumber of Fisher Scoring iterations: 9\n\n\n\n\nVisualizing Predicted Reviews by Room Type\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Exponentiated Coefficients\n\n# View exponentiated coefficients\nexp(coef(poisson_model))\n\n              (Intercept)     room_typePrivate room      room_typeShared room \n               38.3132645                 1.0122050                 0.8047943 \n                bathrooms                  bedrooms                     price \n                0.8953793                 1.0785548                 0.9999630 \nreview_scores_cleanliness    review_scores_location       review_scores_value \n                1.1205166                 0.9223183                 0.9074845 \n     instant_bookableTRUE                      days \n                       NA                 1.0000496 \n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThis model estimates how different features of an Airbnb listing affect the expected number of reviews, which we use as a proxy for how often the listing is booked.\n\nKey Findings:\n\nRoom Type:\n\nPrivate rooms receive about 1.2% more reviews than entire homes.\n\nShared rooms receive about 19.5% fewer reviews, suggesting they are less popular.\n\nBathrooms:\nEach additional bathroom is associated with about 10.5% fewer reviews, possibly because larger properties serve a more niche market.\nBedrooms:\nListings with more bedrooms receive about 7.9% more reviews per extra bedroom, likely due to their suitability for larger groups.\nPrice:\nHigher prices slightly reduce expected bookings, though the effect is very small per dollar.\nCleanliness Score:\nA 1-point increase in cleanliness rating leads to a 12% increase in expected reviews — this is one of the strongest effects, highlighting the importance of cleanliness.\nDays Listed:\nListings that have been active longer receive more reviews, which is expected since they have more exposure.\nInstant Bookable:\nThis feature was excluded due to multicollinearity, meaning it was too similar to other variables to be separately estimated.\n\n\n\n\nSummary\n\nCleanliness, bedroom count, and room type are the most important factors for getting more bookings.\nShared rooms and expensive or oversized listings tend to get booked less often.\nStaying on the platform longer helps accumulate reviews, but maintaining high standards (especially cleanliness) is more impactful.\nThese are associations, not guarantees — but the model gives us a strong idea of what drives listing popularity on Airbnb."
  },
  {
    "objectID": "projects/project3/hw2_questions.html#estimation-of-simple-poisson-model-1",
    "href": "projects/project3/hw2_questions.html#estimation-of-simple-poisson-model-1",
    "title": "Poisson Regression Examples",
    "section": "Estimation of Simple Poisson Model",
    "text": "Estimation of Simple Poisson Model\nSince our outcome variable of interest (number of patents) is a count that can only take non-negative integers, we model it using a Poisson distribution. Specifically, we assume:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda)\n\\]\nThe probability mass function for a Poisson-distributed variable is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nWe now write the likelihood function for a sample of ( n ) independent observations ( Y_1, Y_2, , Y_n ):\n\\[\nL(\\lambda \\mid Y_1, \\dots, Y_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThis simplifies to:\n\\[\nL(\\lambda) = \\frac{e^{-n\\lambda} \\lambda^{\\sum Y_i}}{\\prod_{i=1}^{n} Y_i!}\n\\]\nTaking the natural logarithm gives the log-likelihood function:\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log Y_i!\n\\]\nThis function will form the basis for estimating ( ) via Maximum Likelihood Estimation (MLE).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\nEstimation of Poisson Regression Model\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/project3/hw2_questions.html#deriving-the-mle-for-λ-in-the-poisson-model",
    "href": "projects/project3/hw2_questions.html#deriving-the-mle-for-λ-in-the-poisson-model",
    "title": "Poisson Regression Examples",
    "section": "Deriving the MLE for λ in the Poisson Model",
    "text": "Deriving the MLE for λ in the Poisson Model\nWe begin with the log-likelihood function for a Poisson-distributed variable ( Y_1, , Y_n () ):\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log Y_i!\n\\]\nSince the last term does not depend on ( ), we focus on the first two terms when maximizing:\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum Y_i \\right) \\log \\lambda\n\\]\nTaking the derivative with respect to ( ):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = -n + \\frac{\\sum Y_i}{\\lambda}\n\\]\nSet the derivative equal to zero to find the maximum:\n\\[\n-n + \\frac{\\sum Y_i}{\\lambda} = 0\n\\]\nSolving for ( ):\n\\[\n\\lambda_{\\text{MLE}} = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\nThis result aligns with intuition: the mean of a Poisson distribution is ( ), so the sample mean is the natural estimator.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python. #### Finding the MLE Using optim()\n\n# Negative log-likelihood (since optim minimizes)\nneg_loglik &lt;- function(lambda, Y) {\n  return(-poisson_loglikelihood(lambda, Y))\n}\n\n# Use optim() to find lambda that minimizes the negative log-likelihood\nmle_result &lt;- optim(par = 1, fn = neg_loglik, Y = df$patents, method = \"Brent\", lower = 0.01, upper = 10)\n\n# Print MLE estimate\nlambda_mle &lt;- mle_result$par\nlambda_mle\n\n[1] 3.684667\n\n\n\nEstimation of Poisson Regression Model\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/project3/hw2_questions.html#log-likelihood-plot-with-mle",
    "href": "projects/project3/hw2_questions.html#log-likelihood-plot-with-mle",
    "title": "Poisson Regression Examples",
    "section": "Log-Likelihood Plot with MLE",
    "text": "Log-Likelihood Plot with MLE\n\n\n\n\n\n\n\n\n\n\nEstimation of Poisson Regression Model\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/project3/hw2_questions.html#checking-results-with-glm",
    "href": "projects/project3/hw2_questions.html#checking-results-with-glm",
    "title": "Poisson Regression Examples",
    "section": "Checking Results with glm()",
    "text": "Checking Results with glm()\nTo validate our MLE results, we fit the same Poisson regression model using R’s glm() function with the family = poisson option.\n\n# Fit Poisson regression using glm()\nglm_fit &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n               data = df, family = poisson())\n\n# Summary of model\nsummary(glm_fit)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(), data = df)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.508920   0.183179  -2.778  0.00546 ** \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast  0.029170   0.043625   0.669  0.50372    \nregionNorthwest -0.017574   0.053781  -0.327  0.74383    \nregionSouth      0.056561   0.052662   1.074  0.28281    \nregionSouthwest  0.050576   0.047198   1.072  0.28391    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/project3/hw2_questions.html#estimating-the-effect-of-blueprinty-software",
    "href": "projects/project3/hw2_questions.html#estimating-the-effect-of-blueprinty-software",
    "title": "Poisson Regression Examples",
    "section": "Estimating the Effect of Blueprinty Software",
    "text": "Estimating the Effect of Blueprinty Software\nSince Poisson regression coefficients are on the log scale and not directly interpretable, we estimate the average marginal effect of using Blueprinty software by creating two hypothetical scenarios:\n\nX_0: All firms are non-customers (iscustomer = 0)\nX_1: All firms are customers (iscustomer = 1)\n\nWe then predict patent counts in both cases using the fitted model and compare the difference.\n\n# Step 1: Create X_0 and X_1\nX_0 &lt;- X\nX_1 &lt;- X\nX_0[, \"iscustomer\"] &lt;- 0\nX_1[, \"iscustomer\"] &lt;- 1\n\n# Step 2: Predicted patent counts\neta_0 &lt;- X_0 %*% beta_hat\neta_1 &lt;- X_1 %*% beta_hat\ny_pred_0 &lt;- exp(eta_0)\ny_pred_1 &lt;- exp(eta_1)\n\n# Step 3: Average difference\neffect &lt;- mean(y_pred_1 - y_pred_0)\neffect\n\n[1] 0.2178843\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nOn average, firms predicted to be Blueprinty customers have 0.22 more patents than if they were not customers, holding age and region constant.\nThis provides an interpretable estimate of Blueprinty’s marginal effect and supports the claim that Blueprinty usage is associated with increased patent success."
  }
]